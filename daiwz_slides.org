#+INCLUDE: style/config.org

#+NAME: eval_conf
#+BEGIN_SRC emacs-lisp :results none :exports none
(set 'conf-file (concat default-directory "style/config.el"))
(load conf-file)
#+END_SRC

#+TITLE: 一阶逻辑领域知识与机器学习的结合研究
#+AUTHOR: 戴望州
#+DATE: <2019-02-26 一>

# Title slide
#+BEGIN_EXPORT html
<section id="slide-title">
<img src="./figs/dissertation/nju.jpg" style="position:absolute;top:5%;right:5%;width:300px;box-shadow:none" />
<div class="talk-title">
    <p style="font-size:0.8em;color:rgba(0,0,0,0.6)">博士论文答辩汇报</p>
    <h1 class="no-toc-progress">一阶逻辑领域知识<br>与机器学习的结合研究</h1>
</div>
<div class="talk-subtitle">
    <p>Research on Integrating First-Order Logical Domain Knowledge with Machine Learning</p>
</div>
<div class="keyboard-usage">
    <p>(Press <code>?</code> for help, <code>n</code> and <code>p</code> for next and previous slide)</p>
</div>
<div class="talk-author" style="font-size:0.7em">
    <p>&emsp;<b>答辩人</b>： 戴望州<br />
       &emsp;&emsp;<b>专业</b>： 计算机科学与技术<br />
       <b>研究方向</b>： 机器学习<br />
       <b>指导教师</b>： 周志华 教授<br />
    <span class="talk-date">2019-02-26 星期二</span></p>
</div>
</section>
<!--大纲-->
<section id="slide-toc">
<div class="talk-toc">
    <h3 class="no-toc-progress">大纲</h3>
</div>
#+END_EXPORT
- 研究背景
- 第二、三章：一阶逻辑领域知识辅助的机器学习方法
  - 第二章：一种领域知识增广样本的机器学习方法
  - 第三章：一种领域知识辅助约束的机器学习方法
- 第四章：一种机器学习驱动的领域知识精化方法
- 第五章：一种领域知识与机器学习互促结合框架
- 总结
#+REVEAL_HTML: </section>
* 研究背景
** 人工智能
#+BEGIN_EXPORT html
<div class=flexbox-stretch>
    <img class="fragment appear" data-fragment-index=0
src="https://media.boingboing.net/wp-content/uploads/2018/11/hal.gif" height=180 width=auto />
    <img class="fragment appear" data-fragment-index=0 src="https://media.tenor.com/images/14ea2784dbf2458cc2911e5dac4e4024/tenor.gif" height=180 width=auto />
    <img class="fragment appear" data-fragment-index=0 src="https://i.pinimg.com/originals/6c/fc/5c/6cfc5c281108d8ae10f4d6ced8c34dc6.gif" height=180 width=auto />
    <img class="fragment appear" data-fragment-index=2 src="http://5b0988e595225.cdn.sohucs.com/images/20170727/a6fbd258cec24b81aa29da7747a633c9.png" height=180 width=320 />    
    <img src="https://www.citibank.com.sg/citigold/images/insights/infograph-1a.gif" height=180 width=280 />
    <img class="fragment appear" data-fragment-index=3 src="./figs/dissertation/trump.png" height=180 width=380 />
    <img class="fragment appear" data-fragment-index=1 src="https://storage.googleapis.com/deepmind-live-cms/documents/sc2-agent-vis%2520%25281%2529.gif" height=180 width=auto />
    <img class="fragment appear" data-fragment-index=1 src="https://thumbs.gfycat.com/DeliciousWeepyBullfrog-small.gif" height=180 width=340 />
    <img class="fragment appear" data-fragment-index=1 src="https://thumbs.gfycat.com/AmusingConfusedBobwhite-max-1mb.gif" height=180 width=auto />    
</div>
#+END_EXPORT
*** 早期人工智能
{{{begin_div(flexbox)}}}
{{{begin_div(leftcol60)}}}
- 一般问题求解:
  - General Problem Solver, 1957
  - 自动定理证明, 1960s
- 知识工程:
  - 专家系统, 1960s
  - 逻辑程序, 1970s
  - "五代机", 1980s
{{{end_div()}}}
{{{begin_div(rightcol40)}}}
[[http://diva.library.cmu.edu/Newell/newell-simon.jpg]]
{{{end_div()}}}
{{{end_div()}}}
#+ATTR_HTML: :class org-center fragment appear
{{{bbold(“推理引擎+领域知识”)}}}
#+BEGIN_NOTES
(Simon & Newell 1957), (Gelenter 1959, Robinson 1965), (Feigenbaum et. al. 1960s), (McCarthy et. al. 1960s, Kowalski 1970s), (Japan, 1980s)
#+END_NOTES
*** “知识工程瓶颈”
#+REVEAL_HTML: <img src="https://www.igcseict.info/theory/7_2/expert/files/stacks_image_5738.png" align=center style="margin:10px auto;"/>
#+ATTR_HTML: :style font-size:3em;position:absolute;right:39.5%;top:21% :class fragment appear :data-fragment-index 1
{{{rawesome(157)}}}
#+ATTR_HTML: :style font-size:2em;position:absolute;right:25%;top:18% :class fragment appear :data-fragment-index 2
{{{rawesome(119)}}}
#+ATTR_REVEAL: :frag (appear appear) :frag_idx (1 2)
- 领域知识成本高;
- 某些知识难以总结、专家不愿分享;

#+ATTR_HTML: :class org-center fragment appear
{{{bbold(解决办法: 通过计算、利用经验来改善系统自身性能)}}}
*** 机器学习
{{{begin_div(flexbox)}}}
{{{begin_div(leftcol40)}}}
[[./figs/dissertation/ml.svg]]
{{{end_div()}}}
{{{begin_div(rightcol60)}}}
\[
\min_f E_{\langle x,y\rangle\sim D}loss(f(x),y)
\]
#+BEGIN_EXPORT html
<div class=flexbox-stretch>
    <img class="fragment appear" data-fragment-index=0 src="https://systweak1.vo.llnwd.net/content/wp/systweakblogsnew/uploads_new/2018/03/hidden-layers-in-network.gif" width=290px height=220px/>
    <img class="fragment appear" data-fragment-index=1 src="https://jeremykun.files.wordpress.com/2017/06/svm_solve_by_hand-e1496076457793.gif" width=280px height=220px/>
    <img class="fragment appear" data-fragment-index=2 src="https://yanndubs.github.io/img/blog/decision-tree-class.gif" width=340px height=220px/>
    <img class="fragment appear" data-fragment-index=3 src="https://cdn-images-1.medium.com/max/1600/1*Nx6IyGfRAV1ly6uDGnVCxQ.gif" width=230px height=220px>
</div>
#+END_EXPORT
{{{end_div}}}
{{{end_div}}}
#+BEGIN_NOTES
机器学习的目标，代表性模型有神经网络、支持向量机、决策树等监督学习方法，以及非监督学习方法
#+END_NOTES
** 机器学习中待解决的问题
{{{begin_div(flexbox)}}}
{{{begin_div(leftcol)}}}
- 可理解性
  - Human Aware AI: [[https://aaai.org/Library/Workshops/ws17-10.php][AAAI'17 WS]], [[http://rakaposhi.eas.asu.edu/haai-aaai/AAAI-Presidential-Address-final.pdf][AAAI'18 Presidential Adress]].
  - Interpretable Machine Learning: [[https://nips.cc/Conferences/2017/Schedule?showEvent=8744][NIPS'17 WS]], [[https://sites.google.com/site/nips2016interpretml/][NIPS'16 WS]].
  - Explainable AI (XAI): [[http://home.earthlink.net/~dwaha/research/meetings/faim18-xai/][IJCAI'18 WS]], [[http://home.earthlink.net/~dwaha/research/meetings/ijcai17-xai/][IJCAI'17 WS]], [[https://www.darpa.mil/program/explainable-artificial-intelligence][DARPA Program]].
  - Human in the Loop Machine Learning: [[https://machlearn.gitlab.io/hitl2017/][ICML'17 WS]].
{{{end_div()}}}
{{{begin_div(rightcol)}}}
{{{img(https://imgs.xkcd.com/comics/machine_learning.png, 100%, auto)}}}
{{{end_div()}}}
{{{end_div()}}}
*** TODO 可理解性的来源
{{{begin_div(flexbox)}}}
{{{begin_div(leftcol)}}}
- 机器学习模型本身的结构
  - 逻辑规则，决策树
  - 图模型
  - 线性模型
  - 核方法
  - 深度神经网络
{{{end_div()}}}
{{{begin_div(rightcol)}}}
- 领域知识的形式
  - 特征
{{{end_div()}}}
{{{end_div()}}}
** 一种可能的解决方案
#+ATTR_HTML: :class org-center
{{{rbold(将机器学习与一阶逻辑表示的知识相结合)}}}

{{{begin_div(flexbox-center,font-size:80%)}}}
#+ATTR_HTML: :class fragment appear :data-fragment-index 1 :style text-align:left
*一阶逻辑* (First-Order Logic, FOL)是一种[[https://zh.wikipedia.org/zh-cn/%25E5%25BD%25A2%25E5%25BC%258F%25E8%25AF%25AD%25E8%25A8%2580][形式语言]].
{{{begin_div(leftcol60)}}}
#+ATTR_REVEAL: :frag (appear appear appear appear appear appear appear) :frag_idx (2 2 2 3 3 4 5)
- 常量: $socrates$
- 变量: $X,Y,\ldots$
- 连词: $\wedge,\vee,\neg,\leftarrow,\ldots$
- {{{rbold(谓词/函数)}}}: $mortal/1$, $man/1$
- {{{rbold(量词)}}}: $\forall$, $\exists$
- 项: $man(socrates)$, $mortal(X)$, $\ldots$
- {{{rbold(公式)}}}: $\forall X(mortal(X)\leftarrow man(X)).$
{{{end_div()}}}
{{{begin_div(rightcol40)}}}
#+ATTR_HTML: :height 400px :class fragment appear :data-fragment-index 1
[[http://www.quickmeme.com/img/a3/a31f18eace4a2930460d85351cb584fc88ff5971bddf657816ce54115d9e7cfd.jpg]]
{{{end_div()}}}
{{{end_div()}}}
#+BEGIN_NOTES
什么是一阶逻辑
#+END_NOTES
*** 引入FOL领域知识的好处
{{{begin_div(flexbox)}}}
{{{begin_div(leftcol60)}}}
{{{begin_div(scalebox90,font-size:0.8em)}}}
{{{bold(目标概念)}}}/{{{rbold(发明谓词)}}}/{{{bbold(领域知识)}}}:
\begin{align}
\mathbf{stair}(P)\leftarrow&\color{#981E32}{\mathbf{s}_1}(P).\\
\mathbf{stair}([X,Y,Z|P])\leftarrow&\color{#981E32}{\mathbf{s}_1}(X,Y,Z)\wedge\mathbf{stair}([Z|P]).\\
\color{#981E32}{\mathbf{s}_1}(X,Y,Z)\leftarrow& \color{#1A53A1}{\mathbf{hori}}(X,Y)\wedge\color{#1A53A1}{\mathbf{vert}}(Y,Z).
\end{align}
{{{end_div()}}}
#+REVEAL_HTML: <img src="./figs/dissertation/stairs.svg" height=300px style="box-shadow:none;position:relative;left:21%"/>
{{{end_div()}}}
{{{begin_div(rightcol40)}}}
#+ATTR_REVEAL: :frag (appear)
1. 良好的{{{rbold(可理解性)}}}
   - 模型形式为 $A\leftarrow B_1\wedge\ldots\wedge B_n$
   - 比统计模型和神经网络更易于人类理解   
2. 强大的{{{rbold(表达能力)}}}
   - 允许递归、谓词发明
   - 强于函数形式表达的优化约束
3. 优秀的{{{rbold(推理能力)}}}
   - 是完备的形式系统
{{{end_div()}}}
{{{end_div()}}}
#+BEGIN_NOTES
完备的，意味着所有真命题都可以通过有限步推理证明；那些不可判定的均为假命题。
#+END_NOTES
*** 引入FOL领域知识的其他好处
{{{begin_div(flexbox)}}}
{{{begin_div(leftcol)}}}
- 可重用性
  - 迁移学习（Transfer Learning）
  - 类比推理（Analogical Reasoning）
  - 学件（Learnware）
  - 通用人工智能（Artificial General Intelligence）
- 训练数据量
  - 强化学习（Reinforcement Learning）
{{{end_div()}}}
{{{begin_div(rightcol)}}}
{{{img(./figs/dissertation/learnware.png, 100%, auto)}}}
{{{end_div()}}}
{{{end_div()}}}
*** TODO FOL知识解决了前面的问题
** 本文工作
{{{begin_div(flexbox-center)}}}
[[./figs/dissertation/chpts.svg]]
{{{end_div()}}}
*** 领域知识辅助机器学习
{{{begin_div(flexbox)}}}
{{{begin_div(leftcol65)}}}
- {{{rbold(任务目标)}}}:
  #+ATTR_REVEAL: :frag (appear appear appear) :frag_idx (1 1 2)
  - FOL领域知识完备{{{rawesome(087)}}}
  - 机器学习模型未训练{{{rawesome(165)}}}
  - 利用领域知识提升机器学习性能
- {{{bbold(以往工作)}}}:
  #+ATTR_REVEAL: :frag (appear appear appear) :frag_idx (4 5 6)
  - 可引入函数表达的领域知识
  - {{{bawesome(188)}}}{{{bbold(难点1)}}}：符号表示数据中采用效率更高的统计学习
  - {{{bawesome(188)}}}{{{bbold(难点2)}}}：非符号表示数据中引入FOL领域知识
- {{{bold(本文工作)}}}:
  #+ATTR_REVEAL: :frag (appear appear) :frag_idx (7 7)
  - 第二章：领域知识增广样本（SUL）
  - 第三章：领域知识辅助约束（LASIN）
{{{end_div()}}}
{{{begin_div(rightcol40)}}}
{{{begin_div(scalebox90,font-size:0.8em)}}}
#+BEGIN_EXPORT html
<img src="./figs/dissertation/lasin/data_1.svg" width=200px height="auto" style="position:fixed;right:20%" class="fragment fade-out" data-fragment-index=3 />
<div class="fragment fade-out" data-fragment-index=3>
<div style="font-size:2em;font-weight:bold;position:fixed;right:38.5%;top:62%;">↓</div>
<div style="position: fixed;top: 71%;right: 5%;">特征学习</div>
</div>
#+END_EXPORT
#+ATTR_REVEAL: :frag fade-in :frag_idx 3
\begin{align}
&\mathbf{char}([S|T])\leftarrow\\
&\hspace{3em}\mathbf{stroke}(S)\wedge\mathbf{strokes}(T).\\
&\mathbf{stroke}([A,B,C|T])\leftarrow\\
&\hspace{3em}\mathbf{ink}(A,B)\wedge\mathbf{ink}(B,C)\\
&\hspace{2em}\wedge\mathbf{angle}(\mathbf{AB},\mathbf{BC})<\alpha\\
&\hspace{2em}\wedge\mathbf{stroke}([B,C|T]).
\end{align}
{{{end_div()}}}
#+BEGIN_EXPORT html
<img class="fragment fade-out" data-fragment-index=3 style="position:relative" width="350" height="auto" src="./figs/dissertation/lasin/origin_dict.svg" />
<img class="fragment fade-in" data-fragment-index=3 style="position:fixed;margin:5px;right:0" width="350" height="auto" src="./figs/dissertation/lasin/stroke_dict.svg" />
#+END_EXPORT
{{{end_div()}}}
{{{end_div()}}}
*** 机器学习驱动领域知识精化
{{{begin_div(flexbox)}}}
{{{begin_div(leftcol65)}}}
- {{{rbold(任务目标)}}}:
  #+ATTR_REVEAL: :frag (appear appear appear) :frag_idx (1 1 2)
  - FOL领域知识不完备{{{rawesome(165)}}}
  - 机器学习模型已训练{{{rawesome(087)}}}
  - 利用机器学习驱动FOL知识精化
- {{{bbold(以往工作)}}}:
  #+ATTR_REVEAL: :frag (appear appear) :frag_idx (4 5)
  - 可在FOL表示的数据中对领域知识进行精化，获得FOL规则集
  - {{{bawesome(188)}}}{{{bbold(难点)}}}：在非符号表示的数据中对FOL领域知识进行精化
- {{{bold(本文工作)}}}:
  #+ATTR_REVEAL: :frag (appear) :frag_idx (6)
  - 第四章：机器学习驱动领域知识精化方法（KRL）
{{{end_div()}}}
{{{begin_div(rightcol40)}}}
{{{begin_div(scalebox90,font-size:0.8em)}}}
#+ATTR_REVEAL: :frag fade-out :frag_idx 3
\begin{align}
&\mathbf{polygon}(p1,[(0,0),(0,1),\ldots]).\\
&\mathbf{polygon}(p2,[(2,4),(0,2),\ldots]).\\
&\ldots\\
&\neg\mathbf{regular}(p1).\\
&\mathbf{regular}(p3).\\
&\ldots
\end{align}
{{{end_div()}}}
#+BEGIN_EXPORT html
<img src="./figs/dissertation/logvis/ex_regular.svg" width=350px height="auto" style="position:fixed;top:25%;right:0%" class="fragment fade-in" data-fragment-index=3 />
<div>
<div style="font-size:1em;font-weight:bold;position:fixed;right:18%;top:47%;">↓</div>
<div style="position:fixed;top:47.5%;right:12%;font-size:0.8em">精化</div>
</div>
#+END_EXPORT
{{{begin_div(scalebox90,font-size:0.8em)}}}
\begin{align}
&\mathbf{regular\_poly_2}(A,G)\leftarrow\\
&\hspace{2em}\mathbf{angles\_list}(A,B)\\
&\hspace{1em}\wedge\mathbf{std\_dev\_bounded}(B,G).\\
&\mathbf{regular\_poly_1}(A,A2)\leftarrow\\
&\hspace{2em}\mathbf{polygon}(A,B)\\
&\hspace{1em}\wedge\mathbf{regular\_poly_2}(B,A2).\\
&\mathbf{regular\_poly}(A)\leftarrow\\
&\hspace{2em}\mathbf{regular\_poly_1}(A,0.02).
\end{align}
{{{end_div()}}}
{{{end_div()}}}
{{{end_div()}}}
*** 领域知识与机器学习互促结合
{{{begin_div(flexbox)}}}
{{{begin_div(leftcol65)}}}
- {{{rbold(任务目标)}}}:
  #+ATTR_REVEAL: :frag (appear appear appear) :frag_idx (1 1 2)
  - FOL领域知识不完备{{{rawesome(165)}}}
  - 机器学习模型未训练{{{rawesome(165)}}}
  - 同时进行FOL知识精化与机器学习
- {{{bawesome(188)}}}{{{bbold(挑战)}}}:
  #+ATTR_REVEAL: :frag (appear appear) :frag_idx (4 4)
  - 训练机器学习模型的标记（label）{{{nl()}}}需要通过逻辑推理获得
  - 逻辑推理使用的基本事实（facts）{{{nl()}}}需要借助机器学习识别
- {{{bold(本文工作)}}}:
  #+ATTR_REVEAL: :frag (appear appear) :frag_idx (5)
  - 第五章：领域知识与机器学习{{{nl()}}}互促结合（反绎学习）
{{{end_div()}}}
{{{begin_div(rightcol40)}}}
{{{begin_div(flexbox-center)}}}
#+BEGIN_EXPORT html
<img src="./figs/dissertation/al/before_learn.svg" class="fragment fade-out" style="box-shadow:none;position:fixed;right:0;" data-fragment-index=3 width=350px height=auto />
<img src="./figs/dissertation/al/after_learn.svg" class="fragment fade-in" style="box-shadow:none;position:fixed;right:0" data-fragment-index=3 width=350px height=auto />
#+END_EXPORT
{{{end_div()}}}
{{{end_div()}}}
{{{end_div()}}}
* 第{{{rbold(2)}}}章{{{nl()}}}{{{nl()}}}一种领域知识增广样本的{{{nl()}}}机器学习方法
** 机器学习中的领域知识
{{{begin_div(flexbox-start)}}}
{{{begin_div(leftcol)}}}
{{{bbold(常见的领域知识：)}}}
#+ATTR_REVEAL: :frag (appear appear) :frag_idx (1 9)
- *类型*:
  #+ATTR_REVEAL: :frag (appear appear appear appear) :frag_idx (2 3 4 8)
  - 模型选择
  - 特征工程  
  - 目标函数
    #+ATTR_REVEAL: :frag (appear appear appear) :frag_idx (5 6 7)
    - 损失函数
    - 正则化项
    - 函数空间约束
  - 先验分布
- *特点*: 一般连续可微
#+ATTR_HTML: :class fragment appear :data-fragment-index 19
{{{bbold(常用于SVM、NN，<br />一般作为凸优化约束)}}}
{{{end_div()}}}
{{{begin_div(rightcol)}}}
{{{rbold(FOL领域知识：)}}}
#+ATTR_REVEAL: :frag (appear appear) :frag_idx (10 18)
- *类型*:
  #+ATTR_REVEAL: :frag (appear appear appear) :frag_idx (11 14 17)
  - 标记间的关系
    #+ATTR_REVEAL: :frag (appear appear appear) :frag_idx (12 13)
    - 层次标记
    - 相关性
  - 特征间的关系
    #+ATTR_REVEAL: :frag (appear appear appear) :frag_idx (15 16)
    - 因果关系
    - 相关性
  - 样本间的关系
- *特点*: 离散，关系型知识
#+ATTR_HTML: :class org-center fragment appear :data-fragment-index 20 :style padding:9px 0 0 0
{{{rbold(常用于统计关系学习，<br />一般作为组合优化约束)}}}
{{{end_div()}}}
{{{end_div()}}}
** 引入FOL领域知识的机器学习方法
{{{begin_div(flexbox-center)}}}
{{{begin_div(leftcol)}}}
#+ATTR_REVEAL: :frag (appear appear) :frag_idx (1 3)
- (概率)归纳逻辑程序((P)ILP){{{bsup([])}}}
  #+ATTR_REVEAL: :frag (appear) :frag_idx (4)
  - 模型为FOL规则
- 统计关系学习(SRL){{{bsup([])}}}
  #+ATTR_REVEAL: :frag (appear appear) :frag_idx (5 6)
  - 将逻辑关系解释为相关性
  - FOL规则→概率图模型
{{{begin_div(fragment fade-in,,,8)}}}
{{{rbold(难点)}}}
- FOL规则学习和图模型结构学习均为NP难{{{bsup([])}}}
- 只能用于小数据
{{{end_div()}}}
{{{end_div()}}}
{{{begin_div(rightcol fragment fade-in,,,7)}}}
#+ATTR_HTML: :style margin:5px auto;
[[./figs/dissertation/mln.png]]
{{{begin_div(scalebox60 flex-box,flex-direction:column;margin:0;flex-wrap:none auto;width:450px;height:600px)}}}
\begin{align}
\mathbf{friends}(X,Z)\leftrightarrow&\mathbf{friends}(X,Y)\\
&\wedge \mathbf{friends}(Y,Z).\\
\mathbf{cancer}(X)\leftarrow&\mathbf{smokes}(X).\\
\mathbf{smokes}(Y)\leftarrow&\mathbf{smokes}(X)\\
&\wedge\mathbf{friends}(X,Y).\\
\mathbf{smokes}(X)\leftarrow&\neg\mathbf{friends}(X).
\end{align}
{{{begin_div(,width:700px;font-size:1.19em)}}}
#+BEGIN_SRC prolog :exports code
% (P)ILP与SRL使用的关系型数据集
smokes(alan).      smokes(bob).
friends(alan,bob). friends(bob,charlie).
cancer(charlie).
...
?- cancer(jack).
#+END_SRC
{{{end_div()}}}
{{{end_div()}}}
{{{end_div()}}}
{{{end_div()}}}
*** 基于FOL表示的机器学习方法
{{{begin_div(fragment fade-in,,,1)}}}
- 领域知识库 $KB$ 由FOL规则组成:
\[
A\leftarrow B_1\wedge B_2\wedge\ldots\wedge B_n.
\]
{{{end_div()}}}
{{{begin_div(fragment fade-in,,,2)}}}
- 假设模型 $H=(\Gamma,\theta)$ 由（带权）FOL规则组成:
\[
\color{#981E32}{w::}A\leftarrow B_1\wedge B_2\wedge\ldots\wedge B_n.
\]
{{{end_div}}}
#+ATTR_REVEAL: :frag (appear) :frag_idx (3)
- 学习方式:
  1. 更新规则结构 $\Gamma$;
  2. 最大化似然，求解参数 $\theta$;
  3. 若达到终止条件, 输出 $H=(\Gamma,\theta)$; 否则, goto 2.
{{{begin_div(popupbox fragment fade-in,position:absolute;top:40%;left:4%,,4)}}}
*目标函数不可微，无法使用梯度下降等速度较快的{{{nl}}}优化方法求解*
{{{end_div}}}
#+BEGIN_NOTES
由于领域知识和背景知识采用了相同的形式，归纳逻辑程序设计和统计关系学习均直接对这些领域知识进行利用。
#+END_NOTES
*** 常规机器学习方法
{{{begin_div(flexbox-start)}}}
{{{begin_div(leftcol60)}}}
{{{bbold(问题形式化)}}}
{{{begin_div(fragment fade-in,,,0)}}}
- 经验风险最小化
\begin{equation}
\min_{h\in\mathcal{H}}\frac{1}{m}\sum_{i=1}^mL(h(\mathbf{x}_i),y_i),
\end{equation}
{{{end_div()}}}
{{{end_div()}}}
{{{begin_div(rightcol40 fragment fade-in,width:430px,,1)}}}
{{{rbold(符号表示)}}}
{{{begin_div(,font-size:0.8em)}}}
$\mathbf{x}_i\in\mathcal{X}$: 样本与样本空间{{{nl()}}}
$y_i\in\mathcal{Y}$: 标记与标记空间{{{nl()}}}
$h$: 假设模型{{{nl()}}}
$\mathcal{H}$: 假设空间{{{nl()}}}
$L$: 损失函数
{{{end_div()}}}
{{{end_div()}}}
{{{end_div()}}}
#+ATTR_REVEAL: :frag (appear appear appear) :frag_idx (3 4 5)
1. 利用FOL规则初始化神经网络结构{{{bsup([37\,51\,143\,155])}}};
2. 端到端学习，将FOL知识作为序列输入{{{bsup([57\,58\,170])}}};
3. LDA中将FOL知识作为先验分布或后验分布约束，采用SRL类似的方式学习{{{bsup([2\,102])}}}.
{{{begin_div(popupbox-blue fragment fade-in,position:absolute;top:40%;left:8%,,6)}}}
1. *无法进行真正的逻辑推理*;
2. *基于嵌入表示的模型难以泛化至未见数据*;
3. *仅能使用形式十分受限的FOL规则*.
{{{end_div}}}
** 领域知识增广样本
#+ATTR_HTML: :class org-center fragment fade-in :data-fragment-index 1
{{{rbold(将领域知识 $KB$ 增广样本\,<br/>在新的训练数据集中进行学习)}}}
#+ATTR_HTML: :class fragment fade-in :data-fragment-index 2
\begin{equation}
\min_{h\in\color{#981E32}{\mathcal{H}'}}\frac{1}{m}\sum_{i=1}^mL(h(\mathbf{x}_i,\color{#981E32}{\mathbf{u}_i}),y_i),
\end{equation}
#+ATTR_REVEAL: :frag (appear)
- $\color{#981E32}{\mathbf{u}_i}\in\mathcal{F}$: 由$KB\cup\mathcal{x}_i$ 经过逻辑推理而得到的新信息;
- $\color{#981E32}{\mathcal{H}'}$: 增广后的新假设空间.
*** 领域知识增广样本
{{{bbold(SUL学习(Statistical Unfolded Logic Learning))}}}
#+ATTR_REVEAL: :frag (appear)
1. (Unfold): 将 $KB$ 增广为一组新的特征 $F\in\mathcal{F}$，并将原始特征空间增广为 $\mathcal{X}\times\mathcal{F}$;
2. (Learning): 在新空间中进行机器学习；
3. (Folding): 将学得的模型转化为原始问题假设空间中的模型.
*** 领域知识增广样本
{{{begin_div(flexbox-start)}}}
{{{begin_div(leftcol)}}}
{{{bbold(形式化)}}}
{{{begin_div(fragment fade-in,,,1)}}}
\begin{equation}
B\cup KB\vdash F
\end{equation}
{{{end_div()}}}
{{{begin_div(fragment fade-in,font-size:0.8em,,3)}}}
- 通过 $F$ 提取新特征向量 $\mathbf{u}_i=\langle u_{i1},\ldots,u_{ik}\rangle$, 其中:
#+ATTR_HTML: :style margin:20px 0
\begin{equation}
  u_{ij}=\left\{
      \begin{aligned}
        1,\quad&f_j(\mathbf{x}_i)=true,\\
        0,\quad&f_j(\mathbf{x}_i)=false.\\
      \end{aligned}
    \right.
\end{equation}
{{{end_div()}}}
{{{end_div()}}}
{{{begin_div(rightcol fragment fade-in,,,2)}}}
{{{rbold(符号表示)}}}
#+ATTR_HTML: :style font-size:0.8em;line-height:2.3em
$B=\{\mathbf{x}_1,\ldots,\mathbf{x}_m\}$: 样本(背景知识){{{nl()}}}
$KB$: 领域知识{{{nl()}}}
$\vdash$: 逻辑"推出"{{{nl()}}}
$F=\{f_1,\ldots,f_n\}$: 增广特征
{{{end_div()}}}
{{{end_div()}}}
{{{begin_div(remarkbox fragment fade-in,font-size:0.8em,,4)}}}
"$\vdash$"可用前向链推理{{{bsup([71])}}}实现, 它表示根据 $B\cup KB$ 演绎推理得到 $F.$ 因此这些特征 $f_i\in F$ 作为推理的“结论”均至少包含一部分 $KB$ 中的语义.
{{{end_div()}}}
** 实验验证
{{{bbold(任务：统计关系学习)}}}
#+ATTR_REVEAL: :frag (appear) :frag_idx (1)
- *输入*:
{{{begin_div(fragment fade-in,font-size:80%;width:100%,,1)}}}
#+BEGIN_SRC prolog :exports code
% 基本事实（特征）
author(class_1000,author_m_kearns_).    haswordauthor(author_kearns_michael_, word_michael).
author(class_1001,author_m_j_kearns_).  haswordauthor(author_kearns_m_j_, word_j).
haswordtitle(title_an_introduction_to_computational_learning_theory_, word_an).
haswordvenue(venue_proceedings_sigir_, word_sigir).
title(class_187,title_information_prediction_query_by_comittee_).
venue(class_1221,venue_machine_learning_).
% 样例
sameauthor(author_a_blum_,author_avrim_blum_).
samebib(class_693,class_711).
sametitle(title_warmuth_how_to_use_expert_advice_,title_how_to_use_expert_advice_).
samevenue(venue_19th_symposium_theory_computing_,venue_19th_symposium_theory_computing_).
#+END_SRC
{{{end_div()}}}
#+ATTR_REVEAL: :frag (appear) :frag_idx (2)
- *输出*: 带权逻辑规则集 "$w::A\leftarrow B_1\wedge\ldots\wedge B_n$".
*** 领域知识: 关系型路径
#+REVEAL_HTML: <img src="./figs/dissertation/sul_graph.svg" style="box-shadow:none;margin:20px auto;position:fixed;left:5%" width=1024px class="fragment fade-out" data-fragment-index=1 />
#+REVEAL_HTML: <img src="./figs/dissertation/sul_graph1.svg" style="box-shadow:none;margin:20px auto;position:fixed;left:5%" width=1024px class="fragment fade-in" data-fragment-index=1 />
{{{begin_div(,height:310px;width:1024px)}}}
{{{end_div()}}}
{{{begin_div(remarkbox)}}}
*关系型路径假设* {{{bsup([139])}}} 对于所有正样本事实中的逻辑常量，在基本事实构成的超图中总存在长度有限的路径连接它们.
#+ATTR_HTML: :class org-center :style margin:10px auto
\begin{align}
  \forall i,j\in[1..l](\mathbf{t}(X_1,\ldots,X_l)&\leftarrow i\neq j\wedge \mathbf{path}(X_i,X_j)).\\
  \exists \mathbf{R}(\mathbf{path}(X,Y)&\leftarrow \mathbf{R}(X,Z)\wedge \mathbf{path}(Z,Y)).
\end{align}
{{{end_div}}}
*** 实验设置
#+ATTR_REVEAL: :frag (appear)
- {{{bbold(实验数据)}}}
  - *Cora* {{{bsup([134])}}}: 论文引用条目关系, 数据量大、结构较简单;
    - 4个任务: =author=, =bib=, =title=, =venue=
  - *UW-CSW* {{{bsup([36])}}}: 计算机系成员间关系, 数据量较少、结构复杂.
    - 1个任务: =advisedby=
- {{{rbold(对比方法)}}}
  - *RDN-Boost* {{{bsup([116])}}}: Relational Dependency Network
  - *Alchemy* {{{bsup([36])}}}, *ALEPH++-MLN* {{{bsup([66])}}}: 马尔可夫逻辑网
  - *SUL-Path*: 本文方法
    - 使用三种机器学习模型: =J48=, =AdaBoost= 和 =RandomForest=.
*** 实验结果
{{{bbold(AUC值)}}}
#+ATTR_HTML: :style font-size:66%;margin:30px auto
| 算法            | author           | bib              | title            | venue            | advisedby        |
|-----------------+------------------+------------------+------------------+------------------+------------------|
| SUL-Path-J48    | 0.994 ± 0.004   | 0.926 ± 0.025   | 0.921 ± 0.031   | 0.839 ± 0.046   | 0.633 ± 0.071   |
| SUL-Path-Boost  | *0.998 ± 0.002* | *0.998 ± 0.001* | *0.987 ± 0.011* | *0.977 ± 0.011* | 0.975 ± 0.015   |
| SUL-Path-RF     | *0.998 ± 0.002* | 0.989 ± 0.009   | 0.982 ± 0.017   | 0.946 ± 0.023   | *0.992 ± 0.006* |
| RDN-Boost-org   | 0.985 ± 0.014   | 0.916 ± 0.021   | 0.706 ± 0.121   | 0.589 ± 0.040   | N/A              |
| RDN-Boost-total | 0.986 ± 0.012   | 0.949 ± 0.016   | 0.729 ± 0.126   | 0.590 ± 0.038   | 0.983 ± 0.014   |
| Alchemy         | 0.597 ± 0.152   | N/A              | 0.604 ± 0.216   | N/A              | 0.393 ± 0.103   |
| ALEPH++-MLN     | N/A              | N/A              | N/A              | N/A              | 0.127 ± 0.032   |
*** 实验结果
{{{bbold(学习时间(秒))}}}
#+ATTR_HTML: :style font-size:60%;margin:30px auto
| 算法        | author |   bib |  title | venue | advisedby |
|-------------+--------+-------+--------+-------+-----------|
| SUL-J48     |    0.2 |  87.2 |    0.5 |   1.5 |       0.4 |
| SUL-Boost   |    1.1 | 302.6 |    2.2 |   9.5 |       1.1 |
| SUL-RF      |    1.6 | 471.0 |    4.6 |  19.7 |       1.6 |
| RDN-Boost   |   25.6 | 947.8 |  278.6 | 204.1 |      15.6 |
| Alchemy     | 5232.3 |   N/A | 5898.1 |   N/A |    5478.0 |
| ALEPH++-MLN |    N/A |   N/A |    N/A |   N/A |      0.07 |
{{{bbold(SUL增广样本耗时(秒))}}}
#+ATTR_HTML: :style font-size:60%;margin:30px auto
|           |              |     时间开销 |          | 增广样本大小 |
| /         |            < |            > |        < |            > |
|-----------+--------------+--------------+----------+--------------|
| 任务      | 知识转化特征 | 计算特征向量 | 特征维度 |     样本数量 |
|-----------+--------------+--------------+----------+--------------|
| author    |          5.7 |         13.9 |       36 |         2428 |
| bib       |         47.0 |       1475.5 |       64 |       457782 |
| title     |         20.6 |         80.8 |       34 |        16396 |
| venue     |         55.4 |        491.6 |       33 |        73354 |
| advisedby |         11.5 |         22.7 |      452 |        10625 |
*** 实验结果
{{{bbold(领域知识复杂度与学习模型(J48)性能的关系)}}}
{{{begin_div(flexbox)}}}
#+REVEAL_HTML: <img src="./figs/dissertation/sul/title-len.svg" style="box-shadow:none" width=480px />
#+REVEAL_HTML: <img src="./figs/dissertation/sul/uw-len.svg" style="box-shadow:none" width=480px />
{{{end_div()}}}
#+BEGIN_NOTES
增加路径长度确实对提升 SUL-Path 的表现有所帮助.不过一旦长度超过某个阈值，它带来提升就变得十分有限了.领域知识，关系型路径假设：“有限长度路径”的猜想基本是正确的.

由于 SUL-Path-Boost 和 SUL-Path-RF 的结果已经接近最优，我们选择通过观察SUL-Path-J48 的结果来进研究，该结果如图2.2所示。由于领域内的关系过于复杂，advisedby 任务中当最大路径长度超过 4 时，SUL-Path的展开阶段就无法在 1 小时内结束，因此我们没有计算它的结果.
#+END_NOTES
*** 谓词发明
{{{bbold(习得规则)}}}
\begin{align}
  \mathbf{tree_0\_score}(X_1,X_2,W)\leftarrow & \mathbf{ct\_path}_{0,0}(X_1,X_2,N)\\
  &\hspace{1em}\wedge N > 0.0\wedge W=1.0.
\end{align}
{{{rbold(发明谓词)}}}
\begin{align}
  \mathbf{path}_0(X_1,X_2,X_3,X_4,X_5)\leftarrow & \mathbf{author}(X_3,X_1)\wedge \mathbf{title}(X_3,X_4)\\
  &\hspace{1em}\wedge \mathbf{title}(X_5,X_4)\wedge \mathbf{author}(X_5,X_2).\\
  \mathbf{path}_{0,0}(X_1,X_2,X_3,X_4,X_5)\leftarrow & \mathbf{path}_0(X_1,X_2,X_3,X_4,X_5)\\
  &\hspace{1em}\wedge \mathbf{haswordauthor}(X_1,X_6)\\
  &\hspace{1em}\wedge \mathbf{haswordauthor}(X_2,X_6).
\end{align}
{{{begin_div(popupbox fragment fade-in,position:absolute;top:17%;left:7%;font-size:0.8em,,1)}}}
- $path_0$: 作者 $X_1$ 和 $X_2$ 标题一样的论文；
- $path_{0,0}$: $X_1$ 和 $X_2$ 的名字中至少还拥有一个相同的单词.
{{{end_div()}}}
#+BEGIN_NOTES
借助不同新谓词的组合，SUL-Path可以学得拥有较大长度规则，因此能够表示关系较为复杂的目标概念，这在目前其他的SRL和PILP算法中较难做到。
#+END_NOTES
** 小结
- 提出了SUL方法
  - 将FOL领域知识转化为样本
  - 为常规机器学习方法引入FOL知识
  - 与SRL相比效率更高，可实现谓词发明
{{{begin_div(remarkbox fragment fade-in,font-size:60%;padding:0 15px;height:140px;margin:30px auto,,1)}}}
{{{rbold(相关成果已经发表)}}}
- _W.-Z. Dai_ and Z.-H. Zhou. Statistical unfolded logic learning. In: *Proceedings of the 7th Asian Conference on Machine Learning (ACML’15)*, Hong Kong, China, 2015, JMLR: W&CP 45, pp. 349-361. /(机器学习领域重要国际会议)/
{{{end_div()}}}
* 第{{{rbold(3)}}}章{{{nl()}}}{{{nl()}}}一种领域知识辅助约束的{{{nl()}}}机器学习方法
** 主动假设检验策略
** 领域知识辅助约束
** 实验验证
** 小结
- {{{bbold(现状)}}}
  - KBANN
- {{{rbold(难点)}}}
* 第{{{rbold(4)}}}章{{{nl()}}}{{{nl()}}}一种机器学习驱动的{{{nl()}}}领域知识精化方法
** 
- {{{bbold(现状)}}}
  - 分层学习
  - 神经网络的逻辑规则抽取
- {{{rbold(难点)}}}
  - 需要大量预训练数据
* 第{{{rbold(5)}}}章{{{nl()}}}{{{nl()}}}一种领域知识与机器学习{{{nl()}}}互促结合框架
* 总结
